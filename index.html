<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Xiaofeng Tan </title> <meta name="author" content="Xiaofeng Tan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/0.png?0eff46118615bb79636421eaf5120e16"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://xiaofeng-tan.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/Publications/">Publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <style>.post{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,sans-serif}.post-header{text-align:center;margin-bottom:3rem;padding-bottom:2rem;border-bottom:2px solid #e0e0e0}.post-title{font-size:2.5rem;margin-bottom:.5rem;color:#2c3e50;letter-spacing:-1px;line-height:1.2}.desc{font-size:1rem;color:#7f8c8d;margin-top:.5rem}.desc a{color:#7f8c8d;text-decoration:none;transition:color .3s ease}.desc a:hover{color:#3498db}.section-title{font-size:1.8rem;font-weight:600;color:#2c3e50;margin-top:3rem;margin-bottom:1.5rem;padding-bottom:.5rem;border-bottom:2px solid #e0e0e0;display:flex;align-items:center}.section-title::before{content:'';width:4px;height:1.5rem;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);margin-right:.75rem;border-radius:2px}.education-section{margin-top:2rem;margin-bottom:3rem}.education-list{list-style-type:none;padding:0;margin:0}.education-item{background:linear-gradient(135deg,#fff 0%,#f8f9fa 100%);border-radius:12px;box-shadow:0 4px 12px rgba(0,0,0,0.08);padding:1.5rem;margin-bottom:1.5rem;display:flex;align-items:flex-start;transition:all .3s ease;border:1px solid #f0f0f0}.education-item:hover{transform:translateY(-5px);box-shadow:0 8px 24px rgba(102,126,234,0.15);border-color:#667eea}.education-logo{width:70px;height:70px;margin-right:1.5rem;flex-shrink:0;border-radius:8px;object-fit:cover}.education-details{flex-grow:1}.education-header{display:flex;justify-content:space-between;align-items:baseline;margin-bottom:.5rem;flex-wrap:wrap}.education-school{font-size:1.2rem;font-weight:600;color:#2c3e50}.education-degree{font-size:1rem;color:#34495e;margin-left:.5rem}.education-year{font-size:.9rem;color:#7f8c8d;font-weight:500;background:#f0f0f0;padding:.25rem .75rem;border-radius:20px;margin-left:1rem}.education-intro{font-size:.95rem;color:#555;line-height:1.6;margin:0}.research-section{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,sans-serif;margin-top:2rem;margin-bottom:2rem}.research-title{font-size:1.8rem;font-weight:600;color:#333;margin-bottom:1.5rem;padding-bottom:.5rem;border-bottom:1px solid #e0e0e0}.research-list{list-style-type:none;padding:0}.research-item{background-color:#fff;border-radius:12px;box-shadow:0 4px 12px rgba(0,0,0,0.08);padding:1.5rem;margin-bottom:1.5rem;display:flex;align-items:flex-start;transition:transform .3s ease,box-shadow .3s ease}.research-item:hover{transform:translateY(-5px);box-shadow:0 8px 20px rgba(0,0,0,0.12)}.research-logo{width:65px;height:65px;margin-right:1.5rem;flex-shrink:0}.research-details{flex-grow:1}.research-header{display:flex;justify-content:space-between;align-items:baseline;margin-bottom:.5rem}.research-institution{font-size:1.15rem;font-weight:600;color:#2c3e50}.research-role{font-size:.95rem;color:#e74c3c;font-weight:500;margin-left:.5rem}.research-period{font-size:.9rem;color:#7f8c8d;font-weight:500;flex-shrink:0;margin-left:1rem}.research-lab{font-size:.95rem;color:#34495e;margin-bottom:.3rem}.research-advisor{font-size:.9rem;color:#555;margin-bottom:.5rem}.research-topic{font-size:.95rem;color:#2c3e50;font-weight:500;margin-top:.8rem;margin-bottom:.4rem}.research-topic-content{font-size:.9rem;color:#555;line-height:1.6;margin-bottom:.6rem}.research-output{font-size:.9rem;color:#27ae60;font-weight:500;margin-top:.6rem}.research-output-list{font-size:.9rem;color:#555;line-height:1.6;margin-top:.3rem;padding-left:1.2rem}.research-output-list li{margin-bottom:.3rem}.research-output-section{margin-top:.5rem}.research-output-list{display:inline-flex;flex-wrap:wrap;list-style:none;padding:0;margin:0;gap:.5rem}.research-output-list li{display:inline-block;padding:.25rem .75rem;background-color:#f0f0f0;border-radius:12px;font-size:.9rem;color:#555}.research-output-list li:not(:last-child)::after{content:'‚Ä¢';margin-left:.75rem;color:#999}.honors-section{max-height:400px;overflow-y:auto;padding-right:10px;margin-bottom:2rem}.honors-section::-webkit-scrollbar{width:6px}.honors-section::-webkit-scrollbar-track{background:#f1f1f1;border-radius:10px}.honors-section::-webkit-scrollbar-thumb{background:#667eea;border-radius:10px}.honors-list{list-style:none;padding:0;margin:0}.honors-list li{background:#fff;border-left:4px solid #667eea;padding:1rem 1.25rem;margin-bottom:1rem;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.06);transition:all .3s ease}.honors-list li:hover{transform:translateX(5px);box-shadow:0 4px 12px rgba(102,126,234,0.15);border-left-color:#764ba2}.honor-title{display:flex;justify-content:space-between;align-items:center;margin-bottom:.5rem;flex-wrap:wrap}.honor-title strong{color:#2c3e50;font-size:1.05rem}.year-right{color:#7f8c8d;font-weight:500;background:#f0f0f0;padding:.25rem .75rem;border-radius:20px;font-size:.85rem}.honor-details{font-size:.9rem;color:#555;line-height:1.5}.teaching-section{max-height:350px;overflow-y:auto;padding-right:10px;margin-bottom:2rem}
.teaching-section::-webkit-scrollbar{width:6px}.teaching-section::-webkit-scrollbar-track{background:#f1f1f1;border-radius:10px}.teaching-section::-webkit-scrollbar-thumb{background:#667eea;border-radius:10px}.teaching-list{list-style-type:none;padding:0;margin:0}.teaching-list li{background:#fff;border-left:4px solid #3498db;padding:1rem 1.25rem;margin-bottom:1rem;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.06);transition:all .3s ease}.teaching-list li:hover{transform:translateX(5px);box-shadow:0 4px 12px rgba(52,152,219,0.15);border-left-color:#2980b9}.course-title{display:flex;justify-content:space-between;align-items:center;margin-bottom:.5rem;flex-wrap:wrap}.course-title strong{color:#2c3e50;font-size:1.05rem}.term-right{color:#7f8c8d;font-weight:500;background:#f0f0f0;padding:.25rem .75rem;border-radius:20px;font-size:.85rem}.course-details{font-size:.9rem;color:#555;line-height:1.5}.news{max-height:400px;overflow-y:auto;padding-right:10px;margin-bottom:3rem}.news::-webkit-scrollbar{width:6px}.news::-webkit-scrollbar-track{background:#f1f1f1;border-radius:10px}.news::-webkit-scrollbar-thumb{background:#667eea;border-radius:10px}@media(max-width:768px){.post-title{font-size:2rem}.section-title{font-size:1.5rem}.education-item{flex-direction:column;align-items:center;text-align:center}.education-logo{margin-right:0;margin-bottom:1rem}.education-header{flex-direction:column;align-items:center}.education-year{margin-left:0;margin-top:.5rem}.honor-title,.course-title{flex-direction:column;align-items:flex-start}.year-right,.term-right{margin-top:.5rem}}</style> <div class="post"> <header class="post-header"> <h1 class="post-title"> <strong><span>Xiaofeng</span></strong> <span>Tan</span> <span>(Ë∞≠ÊôìÈîã)</span> </h1> <p class="desc"> <a>M.Sc in Computer Sciences</a> ‚Ä¢ <a>Department of Computer Science and Engineering</a> ‚Ä¢ <a href="https://www.seu.edu.cn" target="_blank" rel="external nofollow noopener">Southeast University</a> </p> </header> </div> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?fb9201aa3256c20eaf462fa760aa4c40" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a second-year M.Sc. student in the <a href="https://palm.seu.edu.cn/" rel="external nofollow noopener" target="_blank">PAttern Learning and Mining (PALM) Lab</a> at <a href="https://www.seu.edu.cn/english/" rel="external nofollow noopener" target="_blank">Southeast University (SEU)</a>, currently exploring new frontiers as a Research Intern at <a href="https://open.youtu.qq.com/#/open" rel="external nofollow noopener" target="_blank">Tencent‚Äôs YouTu Lab</a>.</p> <p>My academic journey began at <a href="https://en.szu.edu.cn/" rel="external nofollow noopener" target="_blank">Shenzhen University (SZU)</a>, where I built a strong interdisciplinary foundation by earning a dual bachelor‚Äôs degree. I graduated with an honors B.E. from the <a href="https://csse.szu.edu.cn/" rel="external nofollow noopener" target="_blank">College of Computer Science and Software Engineering (CSSE)</a> and a B.Sc. from the <a href="https://math.szu.edu.cn/" rel="external nofollow noopener" target="_blank">School of Mathematical Sciences (MS)</a>. It was there, under the mentorship of <a href="https://csse.szu.edu.cn/pages/user/index?id=953" rel="external nofollow noopener" target="_blank">Prof. Can Gao</a>, that I first delved into academic research.</p> <p>My research interests mainly revolve around RLHF, Agentic RL, AIGC, and 3D Human Modeling. Feel free to reach out through <a href="xiaofengtan@seu.edu.cn">email (xiaofengtan@seu.edu.cn)</a> for any questions! I‚Äôm also happy to chat about anything related to Doraemon ü§£.</p> <p>üîç <span style="color:#B22222"><strong>I am currently seeking collaboration opportunities. If you‚Äôre interested, feel free to contact me via <a href="mailto:xiaofengtan@seu.edu.cn" style="color:#2F4F4F">email</a> or <a style="color:#2F4F4F">WeChat</a> (txf_06_20).</strong></span></p> </div> <h2 class="section-title"> <span>üëÄ News</span> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%; color: #666;">Sep 19, 2025</th> <td> üéâ My first-author work, <a href="https://xiaofeng-tan.github.io/projects/SoPo/index.html" rel="external nofollow noopener" target="_blank">SoPo</a>, has been accepted to NeurIPS 2025! </td> </tr> <tr> <th scope="row" style="width: 20%; color: #666;">Jul 01, 2025</th> <td> üëè I become a research intern at <a href="https://open.youtu.qq.com/#/open" rel="external nofollow noopener" target="_blank">Youtu Lab @ Tencent</a>. </td> </tr> <tr> <th scope="row" style="width: 20%; color: #666;">Dec 24, 2024</th> <td> üéâ Merry Xmas! One paper is accepted by <em>IEEE Transactions on Knowledge and Data Engineering</em> ! </td> </tr> <tr> <th scope="row" style="width: 20%; color: #666;">Sep 13, 2024</th> <td> üèÉüèª‚Äç‚û°Ô∏è Officially started my M.Sc journey at SEU. </td> </tr> <tr> <th scope="row" style="width: 20%; color: #666;">Jul 04, 2024</th> <td> üë®üèª‚Äçüéì I graduated from SZU, with an honor B.E degree from CSSE and B.Sc degree from MS. </td> </tr> <tr> <th scope="row" style="width: 20%; color: #666;">Jun 29, 2024</th> <td> üéôÔ∏è I am honored to deliver a speech at the graduation ceremony on behalf of all graduates. [<a href="assets/img/SZU-Speech.jpg">Photos</a>] </td> </tr> <tr> <th scope="row" style="width: 20%; color: #666;">Jun 12, 2024</th> <td> üåà I am honored to be interviewed by SZU as an outstanding student, and is published in the <em>2024 Shenzhen University Admissions Guide</em>. [<a href="https://book.yunzhan365.com/aeeh/bulw/mobile/index.html" rel="external nofollow noopener" target="_blank">Link</a>] </td> </tr> </table> </div> </div> <div class="education-section"> <h2 class="section-title"> <span>üë®üèª‚Äçüéì Education Experience</span> </h2> <ul class="education-list"> <li class="education-item"> <img src="./assets/img/seu_logo.png" alt="Southeast Unversity logo" class="education-logo"> <div class="education-details"> <div class="education-header"> <div> <span class="education-school">Southeast Unversity</span> <span class="education-degree">| Master student</span> </div> <span class="education-year">2024 - Present</span> </div> <p class="education-intro"><em>Outstanding Camper (Ranked 2nd) in 2023 Graduate Admission Summer Camp.</em></p> </div> </li> <li class="education-item"> <img src="/assets/img/szu_logo.png" alt="Shenzhen Unversity logo" class="education-logo"> <div class="education-details"> <div class="education-header"> <div> <span class="education-school">Shenzhen Unversity</span> <span class="education-degree">| Bachelor of Engineering &amp; Bachelor of Science</span> </div> <span class="education-year">2020 - 2024</span> </div> <p class="education-intro"><em>Outstanding Graduate Representative (1/300+) who delivers a speech at the graduation ceremony.</em></p> </div> </li> </ul> </div> <div class="research-section"> <h2 class="research-title"> üî¨ Research Experience </h2> <ul class="research-list"> <li class="research-item"> <img src="/assets/img/tencent-youtu-logo.png" alt="Tencent Inc. logo" class="research-logo"> <div class="research-details"> <div class="research-header"> <div> <span class="research-institution">Tencent Inc.</span> <span class="research-role">| Research Intern</span> </div> <span class="research-period">2025.07 - Present</span> </div> <div class="research-lab"> <strong>Lab:</strong> YouTu Lab </div> <div class="research-output-section"> <strong>Research Works:</strong> <ul class="research-output-list"> <li> </ul> </div> </div> </li> <li class="research-item"> <img src="/assets/img/smu-logo-s.png" alt="Singapore Management University logo" class="research-logo"> <div class="research-details"> <div class="research-header"> <div> <span class="research-institution">Singapore Management University</span> <span class="research-role">| Remote Visiting Student</span> </div> <span class="research-period">2024.07 - 2025.03</span> </div> <div class="research-lab"> <strong>Lab:</strong> Learning and Vision Lab (LV Lab) </div> <div class="research-output-section"> <strong>Research Works:</strong> <ul class="research-output-list"> <li>SoPo (NeurIPS, 2025), ReAlign, BLMotionML3D</li> </ul> </div> </div> </li> <li class="research-item"> <img src="/assets/img/palm-logo.png" alt="Southeast University logo" class="research-logo"> <div class="research-details"> <div class="research-header"> <div> <span class="research-institution">Southeast University</span> <span class="research-role">| Master Student</span> </div> <span class="research-period">2024.04 - 2025.07</span> </div> <div class="research-lab"> <strong>Lab:</strong> PAttern Learning and Mining (PALM) Lab </div> <div class="research-output-section"> <strong>Research Works:</strong> <ul class="research-output-list"> <li>FG-Diff.</li> </ul> </div> </div> </li> <li class="research-item"> <img src="/assets/img/szu_logo.png" alt="Shenzhen University logo" class="research-logo"> <div class="research-details"> <div class="research-header"> <div> <span class="research-institution">Shenzhen University</span> <span class="research-role">| Undergraduate Research Assistant</span> </div> <span class="research-period">2022.10 - 2023.10</span> </div> <div class="research-lab"> <strong>Lab:</strong> Computer Vision Institute </div> <div class="research-output-section"> <strong>Research Works:</strong> <ul class="research-output-list"> <li>MGBOD (TKDE), TWCOD (IJAR)</li> </ul> </div> </div> </li> </ul> </div> <h2 class="section-title"> <span>üìñ Publications</span> </h2> <p style="color: #7f8c8d; font-size: 0.9rem; margin-top: -1rem; margin-bottom: 1.5rem;"> (# denotes co-first Author) </p> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EasyTune-480.webp 480w,/assets/img/publication_preview/EasyTune-800.webp 800w,/assets/img/publication_preview/EasyTune-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/EasyTune.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EasyTune.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Tan2025easytune" class="col-sm-8"> <div class="title">EasyTune: Efficient Step-Aware Fine-Tuning for Diffusion-Based Motion Generation</div> <div class="author"> Xiaofeng Tan#,¬†Wanjiang Weng#,¬†Haodong Lei, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hongsong Wang' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://xiaofeng-tan.github.io/projects/EasyTune/index.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>In recent years, motion generative models have undergone significant advancement, yet pose challenges in aligning with downstream objectives. Recent studies have shown that using differentiable rewards to directly align the preference of diffusion models yields promising results. However, these methods suffer from inefficient and coarse-grained optimization with high memory consumption. In this work, we first theoretically identify the \emphfundamental reason of these limitations: the recursive dependence between different steps in the denoising trajectory. Inspired by this insight, we propose \textbfEasyTune, which fine-tunes diffusion at each denoising step rather than over the entire trajectory. This decouples the recursive dependence, allowing us to perform (1) a dense and effective, (2) memory-efficient, and (3) fine-grained optimization. Furthermore, the scarcity of preference motion pairs restricts the availability of motion reward model training. To this end, we further introduce a \textbfSelf-refinement \textbfPreference \textbfLearning (\textbfSPL) mechanism that dynamically identifies preference pairs and conducts preference learning. Extensive experiments demonstrate that EasyTune outperforms ReFL by 62.1% in MM-Dist improvement while requiring only 34.5% of its additional memory overhead. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ReAlign-480.webp 480w,/assets/img/publication_preview/ReAlign-800.webp 800w,/assets/img/publication_preview/ReAlign-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/ReAlign.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ReAlign.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="weng2024" class="col-sm-8"> <div class="title">Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment</div> <div class="author"> Wanjiang Weng#,¬†Xiaofeng Tan#,¬†Hongsong Wang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Pan Zhou' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://wengwanjiang.github.io/ReAlign-page/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Bilingual text-to-motion generation, which synthesizes 3D human motions from bilingual text inputs, holds immense potential for cross-linguistic applications in gaming, film, and robotics. However, this task faces critical challenges: the absence of bilingual motion-language datasets and the misalignment between text and motion distributions in diffusion models, leading to semantically inconsistent or low-quality motions. To address these challenges, we propose BiHumanML3D, a novel bilingual human motion dataset, which establishes a crucial benchmark for bilingual text-to-motion generation models. Furthermore, we propose a \textbfBilingual \textbfMotion \textbfDiffusion model (\textbfBiMD), which leverages cross-lingual aligned representations to capture semantics, thereby achieving a unified bilingual model. Building upon this, we propose \textbfReward-guided sampling \textbfAlignment (\textbfReAlign) method, comprising a step-aware reward model to assess alignment quality during sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Experiments demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/SoPo-480.webp 480w,/assets/img/publication_preview/SoPo-800.webp 800w,/assets/img/publication_preview/SoPo-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/SoPo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="SoPo.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tan2024sopo" class="col-sm-8"> <div class="title">SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization</div> <div class="author"> <em>Xiaofeng Tan</em>,¬†Hongsong Wang,¬†Xin Geng, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Pan Zhou' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2412.05095 (Under Review)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2412.05095" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/abs/2412.05095" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://arxiv.org/abs/2412.05095" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/Xiaofeng-Tan/SoPO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://xiaofeng-tan.github.io/projects/SoPo/index.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Text-to-motion generation is essential for advancing the creative industry but often presents challenges in producing consistent, realistic motions. To address this, we focus on fine-tuning text-to-motion models to consistently favor high-quality, human-preferred motions‚Äîa critical yet largely unexplored problem. In this work, we theoretically investigate the DPO under both online and offline settings, and reveal their respective limitation: overfitting in offline DPO, and biased sampling in online DPO. Building on our theoretical insights, we introduce Semi-online Preference Optimization (SoPo), a DPO-based method for training text-to-motion models using ‚Äúsemi-online‚Äù data pair, consisting of unpreferred motion from online distribution and preferred motion in offline datasets. This method leverages both online and offline DPO, allowing each to compensate for the other‚Äôs limitations. Extensive experiments demonstrate that SoPo outperforms other preference alignment methods, with an MM-Dist of 3.25% (vs e.g. 0.76% of MoDiPO) on the MLD model, 2.91% (vs e.g. 0.66% of MoDiPO) on MDM model, respectively. Additionally, the MLD model fine-tuned by our SoPo surpasses the SoTA model in terms of R-precision and MM Dist. Visualization results also show the efficacy of our SoPo in preference alignment.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/FGDMAD-480.webp 480w,/assets/img/publication_preview/FGDMAD-800.webp 800w,/assets/img/publication_preview/FGDMAD-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/FGDMAD.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="FGDMAD.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tan2024frequency" class="col-sm-8"> <div class="title">Frequency-Guided Diffusion Model with Perturbation Training for Skeleton-Based Video Anomaly Detection</div> <div class="author"> <em>Xiaofeng Tan</em>,¬†Hongsong Wang,¬†Xin Geng, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Liang Wang' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2412.03044 (Under Review)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2412.03044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/abs/2412.03044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://arxiv.org/abs/2412.03044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/Xiaofeng-Tan/FGDMAD-Code" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://xiaofeng-tan.github.io/projects/FG-Diff/index.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Video anomaly detection is an essential yet challenging open-set task in computer vision, often addressed by leveraging reconstruction as a proxy task. However, existing reconstruction-based methods encounter challenges in two main aspects: (1) limited model robustness for open-set scenarios, (2) and an overemphasis on, but restricted capacity for, detailed motion reconstruction. To this end, we propose a novel frequency-guided diffusion model with perturbation training, which enhances the model robustness by perturbation training and emphasizes the principal motion components guided by motion frequencies. Specifically, we first use a trainable generator to produce perturbative samples for perturbation training of the diffusion model. During the perturbation training phase, the model robustness is enhanced and the domain of the reconstructed model is broadened by training against this generator. Subsequently, perturbative samples are introduced for inference, which impacts the reconstruction of normal and abnormal motions differentially, thereby enhancing their separability. Considering that motion details originate from high-frequency information, we propose a masking method based on 2D discrete cosine transform to separate high-frequency information and low-frequency information. Guided by the high-frequency information from observed motion, the diffusion model can focus on generating low-frequency information, and thus reconstructing the motion accurately. Experimental results on five video anomaly detection datasets, including human-related and open-set benchmarks, demonstrate the effectiveness of the proposed method. The code will be released to the public.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MGBOD-480.webp 480w,/assets/img/publication_preview/MGBOD-800.webp 800w,/assets/img/publication_preview/MGBOD-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MGBOD.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MGBOD.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tanGB" class="col-sm-8"> <div class="title">Fuzzy Granule Density-Based Outlier Detection with Multi-Scale Granular Balls</div> <div class="author"> Can Gao (Supervisor),¬†<em>Xiaofeng Tan<sup>*</sup></em>,¬†Jie Zhou, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Weiping Ding, Witold Pedrycz' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em> IEEE Transactions on Knowledge and Data Engineering</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TKDE.2024.3525003" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/abstract/document/10821488" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Xiaofeng-Tan/MGBOD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://github.com/Xiaofeng-Tan/MGBOD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Outlier detection refers to the identification of anomalous samples that deviate significantly from the distribution of normal data and has been extensively studied and used in a variety of practical tasks. However, most unsupervised outlier detection methods are carefully designed to detect specified outliers, while real-world data may be entangled with different types of outliers. In this study, we propose a fuzzy rough sets-based multi-scale outlier detection method to identify various types of outliers. Specifically, a novel fuzzy rough sets-based method that integrates relative fuzzy granule density is first introduced to improve the capability of detecting local outliers. Then, a multi-scale view generation method based on granular-ball computing is proposed to collaboratively identify group outliers at different levels of granularity. Moreover, reliable outliers and inliers determined by the three-way decision are used to train a weighted support vector machine to further improve the performance of outlier detection. The proposed method innovatively transforms unsupervised outlier detection into a semi-supervised classification problem and for the first time explores the fuzzy rough sets-based outlier detection from the perspective of multi-scale granular balls, allowing for high adaptability to different types of outliers. Extensive experiments carried out on both artificial and UCI datasets demonstrate that the proposed outlier detection method significantly outperforms the state-of-the-art methods, improving the results by at least 8.48% in terms of the Area Under the ROC Curve (AUROC) index.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/TWD-480.webp 480w,/assets/img/publication_preview/TWD-800.webp 800w,/assets/img/publication_preview/TWD-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/TWD.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TWD.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="TANTWD" class="col-sm-8"> <div class="title">Three-way decision-based co-detection for outliers</div> <div class="author"> <em>Xiaofeng Tan</em>,¬†Can Gao,¬†Jie Zhou, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jiajun Wen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>International Journal of Approximate Reasoning</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.ijar.2023.108971" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://www.sciencedirect.com/science/article/pii/S0888613X23001020?via%3Dihub" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Outlier detection is an important research topic in data mining and machine learning. However, existing unsupervised outlier detection methods suffer from irrelevant and redundant attributes in high-dimensional data, and their performance is also limited by their outlier detection models that rely on only one view. In this study, we propose a three-way decision-based co-detection model for unsupervised outlier detection. Specifically, we first improve the local outlier factor (LOF) method by introducing the Gaussian kernel function to make the measure of local reachability density more accurate. Then, we introduce fuzzy rough sets to perform attribute reduction, which further reduces the negative effect of irrelevant and redundant attributes on the measure of sample similarity. Finally, we develop a co-detection model that is trained on the original view and the transformed view generated by principal component analysis and uses the strategy of the three-way decision to collaboratively detect outliers. The results of comparative experiments on the selected UCI datasets show that the proposed model outperforms state-of-the-art methods in terms of AUC-ROC index.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/AEAD-480.webp 480w,/assets/img/publication_preview/AEAD-800.webp 800w,/assets/img/publication_preview/AEAD-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/AEAD.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="AEAD.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tan4785986multiple" class="col-sm-8"> <div class="title">Multi-Scale Fuzzy Rough Sets based Anomaly Detection with Multiple Autoencoders</div> <div class="author"> <em>Xiaofeng Tan</em>,¬†Can Gao,¬†Jie Zhou, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Weiping Ding' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Under Review</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Anomaly detection is a practical and essential research topic with a wide range of applications. However, existing anomaly detection methods may face challenges when handling high-dimensional data with complex distributions. In this study, we propose a multiple autoencoder-based anomaly detection method with the aid of fuzzy rough sets. Specifically, the autoencoder is first improved by introducing the kernel fuzzy relation to enhance its representation capability in low-dimensional space. Then, the theory of fuzzy rough sets is employed to perform anomaly detection in the learned low-dimensional representation by fusing multi-view proximity-based information. Finally, to handle complex data, multiple autoencoders are utilized to collaboratively detect anomalies by integrating local anomaly information from different perspectives. Comparative experiments conducted on the selected datasets reveal that the proposed method is superior to state-of-the-art methods, improving over classical autoencoder by 5.58% in terms of the AUC-ROC index.</p> </div> </div> </div> </li> </ol> </div> <h2 class="section-title"> <span>üåü Selected Honors</span> </h2> <div class="honors-section"> <ul class="honors-list"> <li> <div class="honor-title"> <strong><span>Outstanding Graduate Representative</span></strong> <span class="year-right">2024</span> </div> <div class="honor-details"> Speaker in graduation </div> </li> <li> <div class="honor-title"> <strong><span>Honor Bachelor's Degree</span></strong> <span class="year-right">2024</span> </div> <div class="honor-details"> Top 3% at Shenzhen University </div> </li> <li> <div class="honor-title"> <strong><span>Outstanding Graduate</span></strong> <span class="year-right">2024</span> </div> <div class="honor-details"> Top 5% at Shenzhen University </div> </li> <li> <div class="honor-title"> <strong><span>Star of Liyuan</span></strong> <span class="year-right">2022, 2023</span> </div> <div class="honor-details"> Top 0.73% at Shenzhen University ("Liyuan" means Shenzhen University, ¬•20,000) </div> </li> <li> <div class="honor-title"> <strong><span>Scholarship of Outstanding Innovative Talent</span></strong> <span class="year-right">2020</span> </div> <div class="honor-details"> Top 2% in Guangdong Province Science College Entrance Exam (¬•20,000) </div> </li> </ul> </div> <h2 class="section-title"> <span>üí° Teaching Assistant</span> </h2> <div class="teaching-section"> <ul class="teaching-list"> <li> <div class="course-title"> <strong><span>Fundamentals of Programming</span></strong> <span class="term-right">2022 Fall</span> </div> <div class="course-details"> 2022 Mathematics and Computer Science Special Class, WeBank Fintech Class </div> </li> <li> <div class="course-title"> <strong><span>Data Structure</span></strong> <span class="term-right">2022 Fall, 2023 Fall</span> </div> <div class="course-details"> 2021 and 2022 Computer Science Classes </div> </li> <li> <div class="course-title"> <strong><span>Object-Oriented Programming</span></strong> <span class="term-right">2023 Spring, 2024 Spring</span> </div> <div class="course-details"> 2022 Mathematics and Computer Science Special Class, WeBank Fintech Class, 2023 Computer Science Class </div> </li> <li> <div class="course-title"> <strong><span>Computer System</span></strong> <span class="term-right">2023 Spring</span> </div> <div class="course-details"> 2022 Mathematics and Computer Science Special Class </div> </li> <li> <div class="course-title"> <strong><span>Introduction to Computer Science</span></strong> <span class="term-right">2023 Fall</span> </div> <div class="course-details"> Common Optional Course </div> </li> <li> <div class="course-title"> <strong><span>Operating System</span></strong> <span class="term-right">2024 Spring</span> </div> <div class="course-details"> 2021 Computer Science Class </div> </li> </ul> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%78%69%61%6F%66%65%6E%67%74%61%6E@%73%65%75.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=C2F5mtgAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/Xiaofeng-Tan" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> </div> <div class="contact-note">If you have questions, feel free to reach out through email (xiaofengtan@seu.edu.cn)! </div> </div> </article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Xiaofeng Tan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/Publications/"}},{id:"news-i-am-honored-to-be-interviewed-by-szu-as-an-outstanding-student-and-is-published-in-the-2024-shenzhen-university-admissions-guide-link",title:"\ud83c\udf08 I am honored to be interviewed by SZU as an outstanding student,...",description:"",section:"News"},{id:"news-\ufe0f-i-am-honored-to-deliver-a-speech-at-the-graduation-ceremony-on-behalf-of-all-graduates-photos",title:"\ud83c\udf99\ufe0f I am honored to deliver a speech at the graduation ceremony on...",description:"",section:"News"},{id:"news-i-graduated-from-szu-with-an-honor-b-e-degree-from-csse-and-b-sc-degree-from-ms",title:"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udf93 I graduated from SZU, with an honor B.E degree from CSSE and...",description:"",section:"News"},{id:"news-\ufe0f-officially-started-my-m-sc-journey-at-seu",title:"\ud83c\udfc3\ud83c\udffb\u200d\u27a1\ufe0f Officially started my M.Sc journey at SEU.",description:"",section:"News"},{id:"news-merry-xmas-one-paper-is-accepted-by-ieee-transactions-on-knowledge-and-data-engineering",title:"\ud83c\udf89 Merry Xmas! One paper is accepted by IEEE Transactions on Knowledge and...",description:"",section:"News"},{id:"news-i-become-a-research-intern-at-youtu-lab-tencent",title:"\ud83d\udc4f I become a research intern at Youtu Lab @ Tencent.",description:"",section:"News"},{id:"news-my-first-author-work-sopo-has-been-accepted-to-neurips-2025",title:"\ud83c\udf89 My first-author work, SoPo, has been accepted to NeurIPS 2025!",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%78%69%61%6F%66%65%6E%67%74%61%6E@%73%65%75.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=C2F5mtgAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Xiaofeng-Tan","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>