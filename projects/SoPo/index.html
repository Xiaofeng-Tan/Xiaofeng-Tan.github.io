<style>
  .tldr {
    text-align: left;
    font-size: 0.9em;          /* 比正文略大，温和突出 */
    color: #33333389;            /* 深灰色，稳重且专业 */
    font-style: italic;        /* 斜体正文，区分正文 */
  }
</style>


<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization</title>
  <link rel="icon" type="image/x-icon" href="">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->            
              <span class="author-block">
                <a href="https://xiaofeng-tan.github.io/" target="_blank">Xiaofeng Tan</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a >Hongsong Wang</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a >Xin Geng</a></a><sup>1,2</sup>
                  </span>
                  <span class="author-block">
                    <a >Pan Zhou</a></a><sup>3</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> Department of Computer Science and Engineering, Southeast University, Nanjing, China</span>
                    <span class="author-block"> <sup>2</sup> Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications</span>
                    <span class="author-block">  <sup>3</sup> Singapore Management University</span>
                  </div>
                  <br>
              <p class="tldr" style="max-width: 85%; margin: 0 auto;">
                <strong>TL;DR:</strong> We propose SoPo, a semi-online preference optimization method, combining the strengths of online and offline direct preference optimization to overcome their individual shortcomings, delivering enhanced motion generation quality and preference alignment.
              </p>
              <!-- Paper authors -->            
               <!-- 
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>
                -->
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="./static/pdfs/SoPo__Text_to_Motion_Generation_Using_Semi_Online_Preference_Optimization.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="./static/pdfs/SoPo__Text_to_Motion_Generation_Using_Semi_Online_Preference_Optimization_Supp.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>
                  <!-- End paper abstract -->
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Toy Example </h2>
      <img style="width: 100%; height: auto; display: block; margin: 0 auto;" src="static/images/toy.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-left">
        <strong>Comparison of offline, online DPO, and our SoPo on synthetic data. </strong>Offline DPO suffers from mining unpreferred motions with high probability, and online DPO is limited by biased sampling. Our SoPo utilizes the dynamic unpreferred motions and preferred motions from unbiased offline dataset, overcoming their advantage. Here, the blue region is the distribution of generative model.
      </h2>
      <br>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          </p>
          <p>
            Text-to-motion generation is essential for advancing the creative industry but often presents challenges in producing consistent, realistic motions. To address this, we focus on fine-tuning text-to-motion models to consistently favor high-quality, human-preferred motions—a critical yet largely unexplored problem. In this work, we theoretically investigate the DPO under both online and offline settings, and reveal their respective limitation: overfitting in offline DPO, and biased sampling in online DPO. Building on our theoretical insights, we introduce Semi-online Preference Optimization (SoPo), a DPO-based method for training text-to-motion models using ``semi-online” data pair, consisting of unpreferred motion from online distribution and preferred motion in offline datasets. This method leverages both online and offline DPO, allowing each to compensate for the other’s limitations. Extensive experiments demonstrate that SoPo outperforms other preference alignment methods, with an MM-Dist of 3.25% (vs e.g. 0.76% of MoDiPO) on the MLD model, 2.91% (vs e.g. 0.66% of MoDiPO) on MDM model, respectively. Additionally, the MLD model fine-tuned by our SoPo surpasses the SoTA model in terms of R-precision and MM Dist. Visualization results also show the efficacy of our SoPo in preference alignment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero teaser" style="margin-top: 3rem;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Experiment Results </h2>
      <br>
      <h2 class="subtitle has-text-left">
        <strong>Quantitative results of preference alignment methods for text-to-motion generation on the HumanML3D test set.</strong>
      </h2>
      <img style="width: 100%; height: auto; display: block; margin: 0 auto;" src="static/images/t1.png" alt="MY ALT TEXT"/>
      
      <br>

      <h2 class="subtitle has-text-left">
        <strong>Quantitative comparison of state-of-the-art text-to-motion generation on the HumanML3D test set.</strong>
      </h2>
      <img style="width: 100%; height: auto; display: block; margin: 0 auto;" src="static/images/t2.png" alt="MY ALT TEXT"/>

      <br>

      <h2 class="subtitle has-text-left">
        <strong>Quantitative comparison of state-of-the-art text-to-motion generation on the KIT-ML test set.</strong>
      </h2>
      <img style="width: 60%; height: auto; display: block; margin: 0 auto;" src="static/images/t3.png" alt="MY ALT TEXT"/>

      <br>

      <h2 class="subtitle has-text-left">
        <strong>Ablation studies on the threshold $\tau$ and the number of generated motion.</strong>
      </h2>
      <img style="width: 60%; height: auto; display: block; margin: 0 auto;" src="static/images/t4.png" alt="MY ALT TEXT"/>
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Visual results on HumanML3D dataset</h2>
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/vis.png" alt="MY ALT TEXT"/ style="width: 90%; height: auto; display: block; margin: 0 auto;" >
        <h2 class="subtitle has-text-centered" style="width: 90%; height: auto; display: block; margin: 0 auto;" >
          <strong>Visual results on HumanML3D dataset. We integrate our SoPo into MLD.</strong> Here, the red text denotes descriptions inconsistent with the generated motion.
        </h2>
      </div>
            <br>

            <br>

      <div class="item">
        <!-- Your image here -->
        <img src="static/images/demo01.png" alt="MY ALT TEXT"/ style="width: 90%; height: auto; display: block; margin: 0 auto;" >
        <h2 class="subtitle has-text-centered" style="width: 90%; height: auto; display: block; margin: 0 auto;" >
          <strong>Visual results on HumanML3D dataset. We integrate our SoPo into MDM and MLD, respectively.</strong> Here, the red text denotes descriptions inconsistent with the generated motion.
        </h2>
      </div>
</div>
</div>
</section>
<!-- End image carousel -->



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Visualizations</h2>
      <div class="video-list">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop>
            <source src="static/videos/video_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop>
            <source src="static/videos/video_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop>
            <source src="static/videos/video_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop>
            <source src="static/videos/video_4.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="video5" autoplay controls muted loop>
            <source src="static/videos/video_5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video6">
          <video poster="" id="video6" autoplay controls muted loop>
            <source src="static/videos/video_6.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video7">
          <video poster="" id="video7" autoplay controls muted loop>
            <source src="static/videos/video_7.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video8">
          <video poster="" id="video8" autoplay controls muted loop>
            <source src="static/videos/video_8.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video9">
          <video poster="" id="video9" autoplay controls muted loop>
            <source src="static/videos/video_9.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video10">
          <video poster="" id="video10" autoplay controls muted loop>
            <source src="static/videos/video_10.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video11">
          <video poster="" id="video11" autoplay controls muted loop>
            <source src="static/videos/video_11.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video12">
          <video poster="" id="video12" autoplay controls muted loop>
            <source src="static/videos/video_12.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
